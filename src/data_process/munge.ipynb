{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import lxml.html\n",
    "import random\n",
    "import itertools\n",
    "import math\n",
    "import nltk\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk.corpus import wordnet as w\n",
    "MIN_SENT_LENGTH = 10\n",
    "ENTRY_NUMBER = 5000\n",
    "random_state = 114514"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction functions\n",
    "def sentence_length(text):\n",
    "    text = str(text)\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    numberofsentences = len(sentences)\n",
    "    total_words = 0\n",
    "    for i in sentences:\n",
    "        total_words += len(i.split())\n",
    "    avg_sentence = total_words / numberofsentences\n",
    "    return numberofsentences, avg_sentence\n",
    "\n",
    "def repetitivewords(text):\n",
    "    text = str(text)\n",
    "    token = nltk.word_tokenize(text.lower())\n",
    "    synsets = []\n",
    "    for i in token:\n",
    "        synsets.extend(w.synsets(i))\n",
    "    synonyms = []\n",
    "    for synset in synsets:\n",
    "        synonyms.append([lemma.name() for lemma in synset.lemmas()])\n",
    "    repeat = 0\n",
    "    for index in range(len(synonyms)):\n",
    "        for nextindex in range(index+1, len(synonyms)):\n",
    "            if len(set(synonyms[index]) & set(synonyms[nextindex])) > 0:\n",
    "                repeat += 1\n",
    "    return repeat / len(token)\n",
    "\n",
    "def entropy(text):\n",
    "    text = str(text)\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokennumber = Counter(tokens)\n",
    "    total = len(tokens)\n",
    "    numberofprobs = []\n",
    "    for count in tokennumber.values():\n",
    "        prob = count / total\n",
    "        numberofprobs.append(prob)\n",
    "    entropy = 0.0\n",
    "    for i in numberofprobs:\n",
    "        if i > 0:\n",
    "            entropy -= i * (math.log(i, 2))\n",
    "    return entropy\n",
    "\n",
    "def avg_punctuation():\n",
    "    text = str(text)\n",
    "    num_sent = len(nltk.sent_tokenize(text))\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    punc_count = 0\n",
    "    # what about the ' in there's or I'am ? or quotation mark? or numbered lists?\n",
    "    for t in tokens:\n",
    "        punc_count += 1 if t in string.punctuation else 0\n",
    "    return punc_count / num_sent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>One of the film’s chief strengths is its perfo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The two crashes that claimed the lives of 346 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>In conclusion, the recent video showing the se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3289</th>\n",
       "      <td>With such overwhelming devastation, it can be ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>In the 1970s, Kirstein turned his attention to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>The escalation of tensions between the US and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>The use of language in a court of law is cruci...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3657</th>\n",
       "      <td>Among the nominees for Best Original Screenpla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>Iran has been a hot topic in the news lately, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Another factor that can drive up the cost of a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  generated\n",
       "1316  One of the film’s chief strengths is its perfo...          1\n",
       "9     The two crashes that claimed the lives of 346 ...          1\n",
       "1462  In conclusion, the recent video showing the se...          1\n",
       "3289  With such overwhelming devastation, it can be ...          1\n",
       "3254  In the 1970s, Kirstein turned his attention to...          1\n",
       "...                                                 ...        ...\n",
       "5117  The escalation of tensions between the US and ...          1\n",
       "5543  The use of language in a court of law is cruci...          1\n",
       "3657  Among the nominees for Best Original Screenpla...          1\n",
       "784   Iran has been a hot topic in the news lately, ...          1\n",
       "145   Another factor that can drive up the cost of a...          1\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def munge_turbo(files, set_features = False):\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        lines = open(file).readlines()\n",
    "        text_list = [l.strip() for l in lines]\n",
    "        text_list = list(filter(lambda t: t!= \"\" and len(t.split()) >= MIN_SENT_LENGTH, text_list))\n",
    "        df = pd.DataFrame({'text': text_list,\n",
    "                       'generated': 1})\n",
    "        if set_features:\n",
    "            df['sent_length'], df['avg_sent_length'] = zip(*df['text'].apply(sentence_length))\n",
    "            df['repetitive_words'] = df['text'].apply(repetitivewords)\n",
    "            df['text_entropy'] = df['text'].apply(entropy)\n",
    "        dfs.append(df)\n",
    "    gpt = pd.concat(dfs, ignore_index=True)\n",
    "    if ENTRY_NUMBER:\n",
    "        gpt = gpt.sample(ENTRY_NUMBER, random_state=random_state)\n",
    "    gpt.to_csv('turbo.csv', index=False)\n",
    "    return gpt\n",
    "munge_turbo(glob.glob('../turbo_generator/data/*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13413</th>\n",
       "      <td>Another issue was the controversy surrounding ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9426</th>\n",
       "      <td>The move was met with mixed reactions from the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7257</th>\n",
       "      <td>But as an outsider looking in, I can’t help bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>The answer, according to many Star Trek enthus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>In conclusion, the Five Star Movement’s risk o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16509</th>\n",
       "      <td>Today, the remnants of the Holy Land’s railway...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>Once we find our pack, it’s important to nurtu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9650</th>\n",
       "      <td>One of the standout dishes at Chao Thai Kitche...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7620</th>\n",
       "      <td>Da Toscano is the brainchild of Chef Michael T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16742</th>\n",
       "      <td>The journey was long and grueling, with every ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  generated\n",
       "13413  Another issue was the controversy surrounding ...          1\n",
       "9426   The move was met with mixed reactions from the...          1\n",
       "7257   But as an outsider looking in, I can’t help bu...          1\n",
       "845    The answer, according to many Star Trek enthus...          1\n",
       "3271   In conclusion, the Five Star Movement’s risk o...          1\n",
       "...                                                  ...        ...\n",
       "16509  Today, the remnants of the Holy Land’s railway...          1\n",
       "7185   Once we find our pack, it’s important to nurtu...          1\n",
       "9650   One of the standout dishes at Chao Thai Kitche...          1\n",
       "7620   Da Toscano is the brainchild of Chef Michael T...          1\n",
       "16742  The journey was long and grueling, with every ...          1\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def munge_gpt3(files):\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        lines = open(file).readlines()\n",
    "        text_list = [l.strip() for l in lines]\n",
    "        text_list = list(filter(lambda t: t!= \"\" and len(t.split()) >= 15, text_list))\n",
    "        df = pd.DataFrame({\n",
    "                    'text': text_list,\n",
    "                    'generated': 1,\n",
    "                       })\n",
    "        dfs.append(df)\n",
    "\n",
    "    gpt = pd.concat(dfs, ignore_index=True)\n",
    "    if ENTRY_NUMBER:\n",
    "        gpt = gpt.sample(ENTRY_NUMBER, random_state=random_state)\n",
    "    gpt.to_csv('scraped_gpt3.csv', index=False)\n",
    "    return gpt\n",
    "munge_gpt3(glob.glob('../gpt_scraper/data/*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def munge_gpt(keyword, chunk = True):\n",
    "    dfs = []\n",
    "    files = glob.glob(f'gpt_data/{keyword}*.csv')\n",
    "    for file in files:\n",
    "        raw_df = pd.read_csv(file)\n",
    "        text_list = [str(t).strip() for t in raw_df['text']]\n",
    "        if chunk:\n",
    "            text_list = [t.split('\\n') for t in text_list]\n",
    "            text_list = list(itertools.chain(*text_list))\n",
    "            text_list = list(filter(lambda t: t!= \"\" and len(t.split()) >= MIN_SENT_LENGTH, text_list))\n",
    "        df = pd.DataFrame({'text': text_list,\n",
    "                       'generated': 1})\n",
    "        dfs.append(df)\n",
    "\n",
    "    gpt = pd.concat(dfs, ignore_index=True)\n",
    "    if ENTRY_NUMBER:\n",
    "        gpt = gpt.sample(ENTRY_NUMBER, random_state=random_state)\n",
    "    gpt.to_csv(f'{keyword}.csv', index=False)\n",
    "    return gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165307</th>\n",
       "      <td>The Federal Home and Community-Based Services ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>Snake &amp; Pistol The monkey mask is in a hole to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170212</th>\n",
       "      <td>I am still waiting to hear back on two of the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183081</th>\n",
       "      <td>We have not been able to solve this case, but ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72960</th>\n",
       "      <td>McKenna is getting more benefits than just wit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41502</th>\n",
       "      <td>This section concerns content related to Warcr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131318</th>\n",
       "      <td>The U.S. stationing of an anti-missile defense...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105242</th>\n",
       "      <td>The 2099 panel is one of the highlights of thi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45921</th>\n",
       "      <td>Jackson County officials are interested in own...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86412</th>\n",
       "      <td>Van Gaal added one thing the majority of clubs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  generated\n",
       "165307  The Federal Home and Community-Based Services ...          1\n",
       "1969    Snake & Pistol The monkey mask is in a hole to...          1\n",
       "170212  I am still waiting to hear back on two of the ...          1\n",
       "183081  We have not been able to solve this case, but ...          1\n",
       "72960   McKenna is getting more benefits than just wit...          1\n",
       "...                                                   ...        ...\n",
       "41502   This section concerns content related to Warcr...          1\n",
       "131318  The U.S. stationing of an anti-missile defense...          1\n",
       "105242  The 2099 panel is one of the highlights of thi...          1\n",
       "45921   Jackson County officials are interested in own...          1\n",
       "86412   Van Gaal added one thing the majority of clubs...          1\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "munge_gpt('small-117M-k40')\n",
    "munge_gpt('small-117M')\n",
    "munge_gpt('medium-345M-k40')\n",
    "munge_gpt('medium-345M')\n",
    "munge_gpt('large-762M-k40')\n",
    "munge_gpt('large-762M')\n",
    "munge_gpt('xl-1542M-k40')\n",
    "munge_gpt('xl-1542M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOG_FILE_NUM = 0 # we will be using scraped data only\n",
    "def parse_blog_xml(file):\n",
    "    tree = lxml.html.parse(file)\n",
    "    post_els = tree.findall('.//post')\n",
    "    posts = [p.text.replace('urlLink', '').strip() for p in post_els]\n",
    "    return posts\n",
    "\n",
    "def get_blog_dfs(fake=False):\n",
    "    dfs = []\n",
    "    blog_files = glob.glob('blogs/*.xml')[:BLOG_FILE_NUM]\n",
    "    for file in blog_files:\n",
    "        posts = parse_blog_xml(file)\n",
    "        generated = [1 if random.random() < 0.5 else 0 for _ in posts] if fake else 0\n",
    "        df = pd.DataFrame({'text': posts,\n",
    "                       'generated': generated})\n",
    "        dfs.append(df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_human(fake=False):\n",
    "    dfs = []\n",
    "    nyt_scraped_files = glob.glob('../nyt_scraper/data/*.txt')\n",
    "    for file in nyt_scraped_files:\n",
    "        lines = open(file).readlines()\n",
    "        text_list = [l.strip() for l in lines]\n",
    "        text_list = text_list[1:] # skip titles\n",
    "        text_list = list(filter(lambda t: t!= \"\" and len(t.split()) >= 10, text_list))\n",
    "        generated = [1 if random.random() < 0.5 else 0 for _ in text_list] if fake else 0\n",
    "        df = pd.DataFrame({'text': text_list,\n",
    "                       'generated': generated})\n",
    "        dfs.append(df)\n",
    "\n",
    "    human = pd.concat(dfs, ignore_index=True)\n",
    "    outfile = 'fake.csv' if fake else 'human.csv'\n",
    "    if ENTRY_NUMBER:\n",
    "        human = human.sample(ENTRY_NUMBER, random_state=random_state)\n",
    "    human.to_csv(outfile, index=False)\n",
    "    return human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "human = process_human(False)\n",
    "human = process_human(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
