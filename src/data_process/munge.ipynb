{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import lxml.html\n",
    "import random\n",
    "import itertools\n",
    "import math\n",
    "import nltk\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk.corpus import wordnet as w\n",
    "MIN_SENT_LENGTH = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction functions\n",
    "def sentence_length(text):\n",
    "    text = str(text)\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    numberofsentences = len(sentences)\n",
    "    total_words = 0\n",
    "    for i in sentences:\n",
    "        total_words += len(i.split())\n",
    "    avg_sentence = total_words / numberofsentences\n",
    "    return numberofsentences, avg_sentence\n",
    "\n",
    "def repetitivewords(text):\n",
    "    text = str(text)\n",
    "    token = nltk.word_tokenize(text.lower())\n",
    "    synsets = []\n",
    "    for i in token:\n",
    "        synsets.extend(w.synsets(i))\n",
    "    synonyms = []\n",
    "    for synset in synsets:\n",
    "        synonyms.append([lemma.name() for lemma in synset.lemmas()])\n",
    "    repeat = 0\n",
    "    for index in range(len(synonyms)):\n",
    "        for nextindex in range(index+1, len(synonyms)):\n",
    "            if len(set(synonyms[index]) & set(synonyms[nextindex])) > 0:\n",
    "                repeat += 1\n",
    "    return repeat / len(token)\n",
    "\n",
    "def entropy(text):\n",
    "    text = str(text)\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokennumber = Counter(tokens)\n",
    "    total = len(tokens)\n",
    "    numberofprobs = []\n",
    "    for count in tokennumber.values():\n",
    "        prob = count / total\n",
    "        numberofprobs.append(prob)\n",
    "    entropy = 0.0\n",
    "    for i in numberofprobs:\n",
    "        if i > 0:\n",
    "            entropy -= i * (math.log(i, 2))\n",
    "    return entropy\n",
    "\n",
    "def avg_punctuation():\n",
    "    text = str(text)\n",
    "    num_sent = len(nltk.sent_tokenize(text))\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    punc_count = 0\n",
    "    # what about the ' in there's or I'am ? or quotation mark? or numbered lists?\n",
    "    for t in tokens:\n",
    "        punc_count += 1 if t in string.punctuation else 0\n",
    "    return punc_count / num_sent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As Hong Kong's political turmoil continues, it...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In June 2019, the Hong Kong government propose...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The international community has spoken out, bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to The New York Times, wealthy Hong ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This phenomenon of wealthy residents fleeing t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6270</th>\n",
       "      <td>Firstly, Suleimani was a key figure in Iran's ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6271</th>\n",
       "      <td>Secondly, Suleimani was known to be a close co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6272</th>\n",
       "      <td>However, some analysts argue that the U.S. may...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6273</th>\n",
       "      <td>Furthermore, there are concerns that the U.S. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6274</th>\n",
       "      <td>In conclusion, the U.S. decision to kill Sulei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6275 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  generated\n",
       "0     As Hong Kong's political turmoil continues, it...          1\n",
       "1     In June 2019, the Hong Kong government propose...          1\n",
       "2     The international community has spoken out, bu...          1\n",
       "3     According to The New York Times, wealthy Hong ...          1\n",
       "4     This phenomenon of wealthy residents fleeing t...          1\n",
       "...                                                 ...        ...\n",
       "6270  Firstly, Suleimani was a key figure in Iran's ...          1\n",
       "6271  Secondly, Suleimani was known to be a close co...          1\n",
       "6272  However, some analysts argue that the U.S. may...          1\n",
       "6273  Furthermore, there are concerns that the U.S. ...          1\n",
       "6274  In conclusion, the U.S. decision to kill Sulei...          1\n",
       "\n",
       "[6275 rows x 2 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def munge_turbo(files, set_features = False):\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        lines = open(file).readlines()\n",
    "        text_list = [l.strip() for l in lines]\n",
    "        text_list = list(filter(lambda t: t!= \"\" and len(t.split()) >= MIN_SENT_LENGTH, text_list))\n",
    "        df = pd.DataFrame({'text': text_list,\n",
    "                       'generated': 1})\n",
    "        if set_features:\n",
    "            df['sent_length'], df['avg_sent_length'] = zip(*df['text'].apply(sentence_length))\n",
    "            df['repetitive_words'] = df['text'].apply(repetitivewords)\n",
    "            df['text_entropy'] = df['text'].apply(entropy)\n",
    "        dfs.append(df)\n",
    "    gpt = pd.concat(dfs, ignore_index=True)\n",
    "    gpt.to_csv('turbo.csv', index=False)\n",
    "    return gpt\n",
    "munge_turbo(glob.glob('../turbo_generator/data/*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def munge_gpt3(files):\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        lines = open(file).readlines()\n",
    "        text_list = [l.strip() for l in lines]\n",
    "        text_list = list(filter(lambda t: t!= \"\" and len(t.split()) >= 15, text_list))\n",
    "        df = pd.DataFrame({\n",
    "                    'text': text_list,\n",
    "                       'generated': 1,\n",
    "                    #    'sent_length':[],\n",
    "                    #    'avg_sent_length':[],\n",
    "                    #    'repetitive_words':[],\n",
    "                    #    'text_entropy':[],\n",
    "                    #    'avg_punctuation' :[]\n",
    "                       })\n",
    "        df['sent_length'], df['avg_sent_length'] = zip(*df['text'].apply(sentence_length))\n",
    "        df['repetitive_words'] = df['text'].apply(repetitivewords)\n",
    "        df['text_entropy'] = df['text'].apply(entropy)\n",
    "        dfs.append(df)\n",
    "\n",
    "    gpt = pd.concat(dfs, ignore_index=True)\n",
    "    gpt.to_csv('gpt3.csv', index=False)\n",
    "    return gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_gpt(files, chunk = True):\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        raw_df = pd.read_csv(file)\n",
    "        text_list = [str(t).strip() for t in raw_df['text']]\n",
    "        if chunk:\n",
    "            text_list = [t.split('\\n') for t in text_list]\n",
    "            text_list = list(itertools.chain(*text_list))\n",
    "            text_list = list(filter(lambda t: t!= \"\" and len(t.split()) >= 10, text_list))\n",
    "        df = pd.DataFrame({'text': text_list,\n",
    "                       'generated': 1})\n",
    "        dfs.append(df)\n",
    "\n",
    "    gpt = pd.concat(dfs, ignore_index=True)\n",
    "    gpt.to_csv('gpt.csv', index=False)\n",
    "    return gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When I first heard about what a lot of people ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And so I am quite surprised to hear of this ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a blatant attempt to limit trans* righ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First, let's talk about religious liberty. And...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Now, you may be saying, 'But that doesn't seem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54178</th>\n",
       "      <td>Of course, the inequality gap is not just in a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54179</th>\n",
       "      <td>The growth of wealth inequality has become a g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54180</th>\n",
       "      <td>In short, wealth inequality within and between...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54181</th>\n",
       "      <td>This is where public welfare measures to ensur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54182</th>\n",
       "      <td>The U.S. government -- specifically, the Socia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54183 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  generated\n",
       "0      When I first heard about what a lot of people ...          1\n",
       "1      And so I am quite surprised to hear of this ne...          1\n",
       "2      This is a blatant attempt to limit trans* righ...          1\n",
       "3      First, let's talk about religious liberty. And...          1\n",
       "4      Now, you may be saying, 'But that doesn't seem...          1\n",
       "...                                                  ...        ...\n",
       "54178  Of course, the inequality gap is not just in a...          1\n",
       "54179  The growth of wealth inequality has become a g...          1\n",
       "54180  In short, wealth inequality within and between...          1\n",
       "54181  This is where public welfare measures to ensur...          1\n",
       "54182  The U.S. government -- specifically, the Socia...          1\n",
       "\n",
       "[54183 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenate_gpt(glob.glob('gpt_data/xl-1542M-k40.test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_blog_xml(file):\n",
    "    tree = lxml.html.parse(file)\n",
    "    post_els = tree.findall('.//post')\n",
    "    posts = [p.text.replace('urlLink', '').strip() for p in post_els]\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOG_FILE_NUM = 0 # change this to add blog data\n",
    "def process_human(fake=False):\n",
    "    dfs = []\n",
    "\n",
    "    # files = glob.glob('nyt_data/*.csv')\n",
    "    # for file in files:\n",
    "    #     raw_df = pd.read_csv(file)\n",
    "    #     text_list = [str(t).strip() for t in raw_df['abstract']]\n",
    "    #     generated = [1 if random.random() < 0.5 else 0 for _ in text_list] if fake else 0\n",
    "    #     df = pd.DataFrame({'text': text_list,\n",
    "    #                    'generated': generated})\n",
    "    #     dfs.append(df)\n",
    "\n",
    "    nyt_scraped_files = glob.glob('../nyt_scraper/data/*.txt')\n",
    "    for file in nyt_scraped_files:\n",
    "        lines = open(file).readlines()\n",
    "        text_list = [l.strip() for l in lines]\n",
    "        text_list = text_list[1:] # skip titles\n",
    "        text_list = list(filter(lambda t: t!= \"\" and len(t.split()) >= 10, text_list))\n",
    "        generated = [1 if random.random() < 0.5 else 0 for _ in text_list] if fake else 0\n",
    "        df = pd.DataFrame({'text': text_list,\n",
    "                       'generated': generated})\n",
    "        dfs.append(df)\n",
    "\n",
    "    # blog_files = glob.glob('blogs/*.xml')[:BLOG_FILE_NUM]\n",
    "    # for file in blog_files:\n",
    "    #     posts = parse_blog_xml(file)\n",
    "    #     generated = [1 if random.random() < 0.5 else 0 for _ in posts] if fake else 0\n",
    "    #     df = pd.DataFrame({'text': posts,\n",
    "    #                    'generated': generated})\n",
    "    #     dfs.append(df)\n",
    "\n",
    "    human = pd.concat(dfs, ignore_index=True)\n",
    "    outfile = 'fake.csv' if fake else 'human.csv'\n",
    "    human.to_csv(outfile, index=False)\n",
    "    return human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_human(True)\n",
    "human = process_human(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WASHINGTON — President Trump held what he call...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“I have many issues,” Mr. Trump said in announ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To mark the occasion, several high-ranking adm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The executive order, according to White House,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to Polaris, a nonprofit organization...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94264</th>\n",
       "      <td>The program, The Globe wrote, was “a penetrati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94265</th>\n",
       "      <td>Ms. Jarvis began filming in China in August 19...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94266</th>\n",
       "      <td>Ms. Jarvis left NBC in 1976 and founded her ow...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94267</th>\n",
       "      <td>In addition to “Junon and Avos,” which Ms. Jar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94268</th>\n",
       "      <td>Ms. Jarvis’s husband died in 1999. A daughter,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94269 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  generated\n",
       "0      WASHINGTON — President Trump held what he call...          0\n",
       "1      “I have many issues,” Mr. Trump said in announ...          0\n",
       "2      To mark the occasion, several high-ranking adm...          0\n",
       "3      The executive order, according to White House,...          0\n",
       "4      According to Polaris, a nonprofit organization...          0\n",
       "...                                                  ...        ...\n",
       "94264  The program, The Globe wrote, was “a penetrati...          0\n",
       "94265  Ms. Jarvis began filming in China in August 19...          0\n",
       "94266  Ms. Jarvis left NBC in 1976 and founded her ow...          0\n",
       "94267  In addition to “Junon and Avos,” which Ms. Jar...          0\n",
       "94268  Ms. Jarvis’s husband died in 1999. A daughter,...          0\n",
       "\n",
       "[94269 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
